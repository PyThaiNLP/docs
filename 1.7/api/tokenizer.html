

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>pythainlp.tokenize &mdash; PyThaiNLP 1.7 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="pythainlp.ulmfit" href="ulmfit.html" />
    <link rel="prev" title="pythainlp.tag" href="tag.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> PyThaiNLP
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Package reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="change.html">pythainlp.change</a></li>
<li class="toctree-l1"><a class="reference internal" href="collation.html">pythainlp.collation</a></li>
<li class="toctree-l1"><a class="reference internal" href="date.html">pythainlp.date</a></li>
<li class="toctree-l1"><a class="reference internal" href="ner.html">pythainlp.ner</a></li>
<li class="toctree-l1"><a class="reference internal" href="number.html">pythainlp.number</a></li>
<li class="toctree-l1"><a class="reference internal" href="romanization.html">pythainlp.romanization</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment.html">pythainlp.sentiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="soundex.html">pythainlp.soundex</a></li>
<li class="toctree-l1"><a class="reference internal" href="spell.html">pythainlp.spell</a></li>
<li class="toctree-l1"><a class="reference internal" href="summarize.html">pythainlp.summarize</a></li>
<li class="toctree-l1"><a class="reference internal" href="tag.html">pythainlp.tag</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">pythainlp.tokenize</a></li>
<li class="toctree-l1"><a class="reference internal" href="ulmfit.html">pythainlp.ulmfit</a></li>
<li class="toctree-l1"><a class="reference internal" href="word_vector.html">pythainlp.word_vector</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyThaiNLP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>pythainlp.tokenize</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api/tokenizer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pythainlp-tokenize">
<span id="tokenize-doc"></span><h1>pythainlp.tokenize<a class="headerlink" href="#pythainlp-tokenize" title="Permalink to this headline">¶</a></h1>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">pythainlp.tokenize</span></code> contains multiple functions for tokenizing a chunk of Thai text into desirable units.</p>
<dl class="py function">
<dt id="pythainlp.tokenize.word_tokenize">
<code class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></code><code class="sig-name descname"><span class="pre">word_tokenize</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'newmm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whitespaces</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize.html#word_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.word_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – the text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – the engine to tokenize text</p></li>
<li><p><strong>whitespaces</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – True to output no whitespace, a common mark of sentence or end of phrase in Thai.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters for engine</dt>
<dd class="field-even"><ul class="simple">
<li><p>newmm - Maximum Matching algorithm + TCC</p></li>
<li><p>icu -  IBM ICU</p></li>
<li><p>longest-matching - Longest matching</p></li>
<li><p>mm - Maximum Matching algorithm</p></li>
<li><p>pylexto - LexTo</p></li>
<li><p>deepcut - Deep Neural Network</p></li>
<li><p>wordcutpy - wordcutpy (<a class="reference external" href="https://github.com/veer66/wordcutpy">https://github.com/veer66/wordcutpy</a>)</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of words, tokenized from a text</p>
</dd>
</dl>
<p><strong>Example</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="n">text</span><span class="o">=</span><span class="s1">&#39;ผมรักคุณนะครับโอเคบ่พวกเราเป็นคนไทยรักภาษาไทยภาษาบ้านเกิด&#39;</span>
<span class="n">a</span><span class="o">=</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;icu&#39;</span><span class="p">)</span> <span class="c1"># [&#39;ผม&#39;, &#39;รัก&#39;, &#39;คุณ&#39;, &#39;นะ&#39;, &#39;ครับ&#39;, &#39;โอ&#39;, &#39;เค&#39;, &#39;บ่&#39;, &#39;พวก&#39;, &#39;เรา&#39;, &#39;เป็น&#39;, &#39;คน&#39;, &#39;ไทย&#39;, &#39;รัก&#39;, &#39;ภาษา&#39;, &#39;ไทย&#39;, &#39;ภาษา&#39;, &#39;บ้าน&#39;, &#39;เกิด&#39;]</span>
<span class="n">b</span><span class="o">=</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;dict&#39;</span><span class="p">)</span> <span class="c1"># [&#39;ผม&#39;, &#39;รัก&#39;, &#39;คุณ&#39;, &#39;นะ&#39;, &#39;ครับ&#39;, &#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;เป็น&#39;, &#39;คนไทย&#39;, &#39;รัก&#39;, &#39;ภาษาไทย&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>
<span class="n">c</span><span class="o">=</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;mm&#39;</span><span class="p">)</span> <span class="c1"># [&#39;ผม&#39;, &#39;รัก&#39;, &#39;คุณ&#39;, &#39;นะ&#39;, &#39;ครับ&#39;, &#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;เป็น&#39;, &#39;คนไทย&#39;, &#39;รัก&#39;, &#39;ภาษาไทย&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>
<span class="n">d</span><span class="o">=</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;pylexto&#39;</span><span class="p">)</span> <span class="c1"># [&#39;ผม&#39;, &#39;รัก&#39;, &#39;คุณ&#39;, &#39;นะ&#39;, &#39;ครับ&#39;, &#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;เป็น&#39;, &#39;คนไทย&#39;, &#39;รัก&#39;, &#39;ภาษาไทย&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>
<span class="n">e</span><span class="o">=</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;newmm&#39;</span><span class="p">)</span> <span class="c1"># [&#39;ผม&#39;, &#39;รัก&#39;, &#39;คุณ&#39;, &#39;นะ&#39;, &#39;ครับ&#39;, &#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;เป็น&#39;, &#39;คนไทย&#39;, &#39;รัก&#39;, &#39;ภาษาไทย&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>
<span class="n">g</span><span class="o">=</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;wordcutpy&#39;</span><span class="p">)</span> <span class="c1"># [&#39;ผม&#39;, &#39;รัก&#39;, &#39;คุณ&#39;, &#39;นะ&#39;, &#39;ครับ&#39;, &#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;เป็น&#39;, &#39;คน&#39;, &#39;ไทย&#39;, &#39;รัก&#39;, &#39;ภาษา&#39;, &#39;ไทย&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="pythainlp.tokenize.dict_word_tokenize">
<code class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></code><code class="sig-name descname"><span class="pre">dict_word_tokenize</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict_trie</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'newmm'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize.html#dict_word_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.dict_word_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference internal" href="#pythainlp.tokenize.dict_word_tokenize" title="pythainlp.tokenize.dict_word_tokenize"><code class="xref py py-meth docutils literal notranslate"><span class="pre">dict_word_tokenize()</span></code></a> tokenizes word based on the dictionary you provide. The format has to be in trie data structure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – the text to be tokenized</p></li>
<li><p><strong>custom_dict_trie</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a>) – คือ trie ที่สร้างจาก create_custom_dict_trie</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – choose between different options of engine to token (newmm, wordcutpy, mm, longest-matching)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of words, tokenized from a text.</p>
</dd>
</dl>
<dl>
<dt><strong>Example</strong>::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">dict_word_tokenize</span><span class="p">,</span><span class="n">create_custom_dict_trie</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">listword</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;แมว&#39;</span><span class="p">,</span><span class="s2">&quot;ดี&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_dict</span><span class="o">=</span><span class="n">create_custom_dict_trie</span><span class="p">(</span><span class="n">listword</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dict_word_tokenize</span><span class="p">(</span><span class="s2">&quot;แมวดีดีแมว&quot;</span><span class="p">,</span><span class="n">data_dict</span><span class="p">)</span>
<span class="go">[&#39;แมว&#39;, &#39;ดี&#39;, &#39;ดี&#39;, &#39;แมว&#39;]</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pythainlp.tokenize.subword_tokenize">
<code class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></code><code class="sig-name descname"><span class="pre">subword_tokenize</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tcc'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize.html#subword_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.subword_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – choosing ‘tcc’ uses the Thai Character Cluster rule to segment words into the smallest unique units.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list of tokenized strings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pythainlp.tokenize.sent_tokenize">
<code class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></code><code class="sig-name descname"><span class="pre">sent_tokenize</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'whitespace+newline'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize.html#sent_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.sent_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>This function does not yet automatically recognize when a sentence actually ends. Rather it helps split text where white space and a new line is found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – the text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – choose between ‘whitespace’ or ‘whitespace+newline’</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list of text, split by whitespace or new line.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pythainlp.tokenize.isthai">
<code class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></code><code class="sig-name descname"><span class="pre">isthai</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize.html#isthai"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.isthai" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – input string or list of strings</p></li>
<li><p><strong>check_all</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – checks all character or not</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the first value as proportional of text that is Thai, and the second value being a tuple of all characters, along with true or false.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pythainlp.tokenize.create_custom_dict_trie">
<code class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></code><code class="sig-name descname"><span class="pre">create_custom_dict_trie</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">custom_dict_source</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize.html#create_custom_dict_trie"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.create_custom_dict_trie" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used to create a custom dict trie which will be used for word_tokenize() function. For more information on the trie data structure, see: <a class="reference external" href="https://marisa-trie.readthedocs.io/en/latest/index.html">https://marisa-trie.readthedocs.io/en/latest/index.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>custom_dict_source</strong> (<em>string/list</em>) – a list of vocaburaries or a path to source file</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A trie created from custom dict input</p>
</dd>
</dl>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="ulmfit.html" class="btn btn-neutral float-right" title="pythainlp.ulmfit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="tag.html" class="btn btn-neutral float-left" title="pythainlp.tag" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017-2021, PyThaiNLP (Apache Software License 2.0).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>