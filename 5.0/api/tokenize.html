<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pythainlp.tokenize &mdash; PyThaiNLP 8b696ac documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css?v=eea1f72d" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=87805c27"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="pythainlp.tools" href="tools.html" />
    <link rel="prev" title="pythainlp.tag" href="tag.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PyThaiNLP
          </a>
              <div class="version">
                dev (8b696ac) <br /> Published date: 10/02/2024
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/FAQ.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/command_line.html">Command Line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/getting_started.html#tutorial-notebooks">Tutorial Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html#faq">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ancient.html">pythainlp.ancient</a></li>
<li class="toctree-l1"><a class="reference internal" href="augment.html">pythainlp.augment</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks.html">pythainlp.benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="chat.html">pythainlp.chat</a></li>
<li class="toctree-l1"><a class="reference internal" href="classify.html">pythainlp.classify</a></li>
<li class="toctree-l1"><a class="reference internal" href="coref.html">pythainlp.coref</a></li>
<li class="toctree-l1"><a class="reference internal" href="corpus.html">pythainlp.corpus</a></li>
<li class="toctree-l1"><a class="reference internal" href="el.html">pythainlp.el</a></li>
<li class="toctree-l1"><a class="reference internal" href="generate.html">pythainlp.generate</a></li>
<li class="toctree-l1"><a class="reference internal" href="khavee.html">pythainlp.khavee</a></li>
<li class="toctree-l1"><a class="reference internal" href="morpheme.html">pythainlp.morpheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="parse.html">pythainlp.parse</a></li>
<li class="toctree-l1"><a class="reference internal" href="phayathaibert.html">pythainlp.phayathaibert</a></li>
<li class="toctree-l1"><a class="reference internal" href="soundex.html">pythainlp.soundex</a></li>
<li class="toctree-l1"><a class="reference internal" href="spell.html">pythainlp.spell</a></li>
<li class="toctree-l1"><a class="reference internal" href="summarize.html">pythainlp.summarize</a></li>
<li class="toctree-l1"><a class="reference internal" href="tag.html">pythainlp.tag</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">pythainlp.tokenize</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#modules">Modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.Tokenizer"><code class="docutils literal notranslate"><span class="pre">Tokenizer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.Tokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">Tokenizer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.Tokenizer.word_tokenize"><code class="docutils literal notranslate"><span class="pre">Tokenizer.word_tokenize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.Tokenizer.set_tokenize_engine"><code class="docutils literal notranslate"><span class="pre">Tokenizer.set_tokenize_engine()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tokenization-engines">Tokenization Engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sentence-level">Sentence level</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.crfcut.extract_features"><code class="docutils literal notranslate"><span class="pre">extract_features()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.crfcut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.thaisumcut.list_to_string"><code class="docutils literal notranslate"><span class="pre">list_to_string()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.thaisumcut.middle_cut"><code class="docutils literal notranslate"><span class="pre">middle_cut()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.thaisumcut.ThaiSentenceSegmentor"><code class="docutils literal notranslate"><span class="pre">ThaiSentenceSegmentor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.thaisumcut.ThaiSentenceSegmentor.split_into_sentences"><code class="docutils literal notranslate"><span class="pre">ThaiSentenceSegmentor.split_into_sentences()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#word-level">Word level</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.attacut.AttacutTokenizer"><code class="docutils literal notranslate"><span class="pre">AttacutTokenizer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.attacut.AttacutTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">AttacutTokenizer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.attacut.AttacutTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">AttacutTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.attacut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.deepcut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.multi_cut.LatticeString"><code class="docutils literal notranslate"><span class="pre">LatticeString</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.multi_cut.LatticeString.__init__"><code class="docutils literal notranslate"><span class="pre">LatticeString.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.multi_cut.mmcut"><code class="docutils literal notranslate"><span class="pre">mmcut()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.multi_cut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.multi_cut.find_all_segment"><code class="docutils literal notranslate"><span class="pre">find_all_segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.nlpo3.load_dict"><code class="docutils literal notranslate"><span class="pre">load_dict()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.nlpo3.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.longest.LongestMatchTokenizer"><code class="docutils literal notranslate"><span class="pre">LongestMatchTokenizer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.longest.LongestMatchTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">LongestMatchTokenizer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.longest.LongestMatchTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">LongestMatchTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.longest.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.pyicu.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.nercut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.sefr_cut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.oskut.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.newmm.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#subword-level">Subword level</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.tcc.tcc"><code class="docutils literal notranslate"><span class="pre">tcc()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.tcc.tcc_pos"><code class="docutils literal notranslate"><span class="pre">tcc_pos()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.tcc.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.tcc_p.tcc"><code class="docutils literal notranslate"><span class="pre">tcc()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.tcc_p.tcc_pos"><code class="docutils literal notranslate"><span class="pre">tcc_pos()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.tcc_p.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.etcc.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.han_solo.Featurizer"><code class="docutils literal notranslate"><span class="pre">Featurizer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.han_solo.Featurizer.__init__"><code class="docutils literal notranslate"><span class="pre">Featurizer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.han_solo.Featurizer.pad"><code class="docutils literal notranslate"><span class="pre">Featurizer.pad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pythainlp.tokenize.han_solo.Featurizer.featurize"><code class="docutils literal notranslate"><span class="pre">Featurizer.featurize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pythainlp.tokenize.han_solo.segment"><code class="docutils literal notranslate"><span class="pre">segment()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">pythainlp.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="translate.html">pythainlp.translate</a></li>
<li class="toctree-l1"><a class="reference internal" href="transliterate.html">pythainlp.transliterate</a></li>
<li class="toctree-l1"><a class="reference internal" href="ulmfit.html">pythainlp.ulmfit</a></li>
<li class="toctree-l1"><a class="reference internal" href="util.html">pythainlp.util</a></li>
<li class="toctree-l1"><a class="reference internal" href="wangchanberta.html">pythainlp.wangchanberta</a></li>
<li class="toctree-l1"><a class="reference internal" href="word_vector.html">pythainlp.word_vector</a></li>
<li class="toctree-l1"><a class="reference internal" href="wsd.html">pythainlp.wsd</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyThaiNLP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">pythainlp.tokenize</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/tokenize.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pythainlp-tokenize">
<span id="tokenize-doc"></span><h1>pythainlp.tokenize<a class="headerlink" href="#pythainlp-tokenize" title="Permalink to this heading"></a></h1>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">pythainlp.tokenize</span></code> module contains a comprehensive set of functions and classes for tokenizing Thai text into various units, such as sentences, words, subwords, and more. This module is a fundamental component of the PyThaiNLP library, providing tools for natural language processing in the Thai language.</p>
<section id="modules">
<h2>Modules<a class="headerlink" href="#modules" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">clause_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">doc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#clause_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Clause tokenizer. (or Clause segmentation)
Tokenizes running word list into list of clauses (list of strings).
Split by CRF trained on Blackboard Treebank.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>doc</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – word list to be clause tokenized</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of clauses</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]]</p>
</dd>
<dt class="field-even">Example<span class="colon">:</span></dt>
<dd class="field-even"><p></p></dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">clause_tokenize</span>
<span class="n">clause_tokenize</span><span class="p">([</span><span class="s2">&quot;ฉัน&quot;</span><span class="p">,</span><span class="s2">&quot;นอน&quot;</span><span class="p">,</span><span class="s2">&quot;และ&quot;</span><span class="p">,</span><span class="s2">&quot;คุณ&quot;</span><span class="p">,</span><span class="s2">&quot;เล่น&quot;</span><span class="p">,</span><span class="s2">&quot;มือถือ&quot;</span><span class="p">,</span><span class="s2">&quot;ส่วน&quot;</span><span class="p">,</span><span class="s2">&quot;น้อง&quot;</span><span class="p">,</span><span class="s2">&quot;เขียน&quot;</span><span class="p">,</span><span class="s2">&quot;โปรแกรม&quot;</span><span class="p">])</span>
<span class="c1"># [[&#39;ฉัน&#39;, &#39;นอน&#39;],</span>
<span class="c1"># [&#39;และ&#39;, &#39;คุณ&#39;, &#39;เล่น&#39;, &#39;มือถือ&#39;],</span>
<span class="c1"># [&#39;ส่วน&#39;, &#39;น้อง&#39;, &#39;เขียน&#39;, &#39;โปรแกรม&#39;]]</span>
</pre></div>
</div>
<p>Tokenizes text into clauses. This function allows you to split text into meaningful sections, making it useful for more advanced text processing tasks.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">sent_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'crfcut'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#sent_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Sentence tokenizer.</p>
<p>Tokenizes running text into “sentences”</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – the text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – choose among <em>‘crfcut’</em>, <em>‘whitespace’</em>,     <em>‘whitespace+newline’</em></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of split sentences</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
<dl class="simple">
<dt><strong>Options for engine</strong></dt><dd><ul class="simple">
<li><p><em>crfcut</em> - (default) split by CRF trained on TED dataset</p></li>
<li><p><em>thaisum</em> - The implementation of sentence segmenter from             Nakhun Chumpolsathien, 2020</p></li>
<li><p><em>tltk</em> - split by <a class="reference external" href="https://pypi.org/project/tltk/">TLTK</a>.,</p></li>
<li><p><em>wtp</em> - split by <a class="reference external" href="https://github.com/bminixhofer/wtpsplit">wtpsplitaxe</a>.,             It supports many sizes of models. You can use <code class="docutils literal notranslate"><span class="pre">wtp</span></code> to use mini model,             <code class="docutils literal notranslate"><span class="pre">wtp-tiny</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-bert-tiny</span></code> model (default),             <code class="docutils literal notranslate"><span class="pre">wtp-mini</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-bert-mini</span></code> model,             <code class="docutils literal notranslate"><span class="pre">wtp-base</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-canine-s-1l</span></code> model,             and <code class="docutils literal notranslate"><span class="pre">wtp-large</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-canine-s-12l</span></code> model.</p></li>
<li><p><em>whitespace+newline</em> - split by whitespace and newline.</p></li>
<li><p><em>whitespace</em> - split by whitespace, specifically with                          <code class="xref py py-class docutils literal notranslate"><span class="pre">regex</span></code> pattern  <code class="docutils literal notranslate"><span class="pre">r&quot;</span> <span class="pre">+&quot;</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Example<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>Split the text based on <em>whitespace</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">sent_tokenize</span>

<span class="n">sentence_1</span> <span class="o">=</span> <span class="s2">&quot;ฉันไปประชุมเมื่อวันที่ 11 มีนาคม&quot;</span>
<span class="n">sentence_2</span> <span class="o">=</span> <span class="s2">&quot;ข้าราชการได้รับการหมุนเวียนเป็นระยะ </span><span class="se">\</span>
<span class="s2">และได้รับมอบหมายให้ประจำในระดับภูมิภาค&quot;</span>

<span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sentence_1</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;whitespace&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ฉันไปประชุมเมื่อวันที่&#39;, &#39;11&#39;, &#39;มีนาคม&#39;]</span>

<span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sentence_2</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;whitespace&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ข้าราชการได้รับการหมุนเวียนเป็นระยะ&#39;,</span>
<span class="c1">#   &#39;\nและได้รับมอบหมายให้ประจำในระดับภูมิภาค&#39;]</span>
</pre></div>
</div>
<p>Split the text based on <em>whitespace</em> and <em>newline</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sentence_1</span> <span class="o">=</span> <span class="s2">&quot;ฉันไปประชุมเมื่อวันที่ 11 มีนาคม&quot;</span>
<span class="n">sentence_2</span> <span class="o">=</span> <span class="s2">&quot;ข้าราชการได้รับการหมุนเวียนเป็นระยะ </span><span class="se">\</span>
<span class="s2">และได้รับมอบหมายให้ประจำในระดับภูมิภาค&quot;</span>

<span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sentence_1</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;whitespace+newline&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ฉันไปประชุมเมื่อวันที่&#39;, &#39;11&#39;, &#39;มีนาคม&#39;]</span>
<span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sentence_2</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;whitespace+newline&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ข้าราชการได้รับการหมุนเวียนเป็นระยะ&#39;,</span>
<span class="s1">&#39;</span><span class="se">\n</span><span class="s1">และได้รับมอบหมายให้ประจำในระดับภูมิภาค&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Split the text using CRF trained on TED dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sentence_1</span> <span class="o">=</span> <span class="s2">&quot;ฉันไปประชุมเมื่อวันที่ 11 มีนาคม&quot;</span>
<span class="n">sentence_2</span> <span class="o">=</span> <span class="s2">&quot;ข้าราชการได้รับการหมุนเวียนเป็นระยะ </span><span class="se">\</span>
<span class="s2">และเขาได้รับมอบหมายให้ประจำในระดับภูมิภาค&quot;</span>

<span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sentence_1</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;crfcut&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ฉันไปประชุมเมื่อวันที่ 11 มีนาคม&#39;]</span>

<span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sentence_2</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;crfcut&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ข้าราชการได้รับการหมุนเวียนเป็นระยะ &#39;,</span>
<span class="s1">&#39;และเขาได้รับมอบหมายให้ประจำในระดับภูมิภาค&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Splits Thai text into sentences. This function identifies sentence boundaries, which is essential for text segmentation and analysis.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">paragraph_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'wtp-mini'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paragraph_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">style</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'newline'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#paragraph_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Paragraph tokenizer.</p>
<p>Tokenizes text into paragraphs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – the name of paragraph tokenizer</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of paragraphs</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]]</p>
</dd>
</dl>
<dl class="simple">
<dt><strong>Options for engine</strong></dt><dd><ul class="simple">
<li><p><em>wtp</em> - split by <a class="reference external" href="https://github.com/bminixhofer/wtpsplit">wtpsplitaxe</a>.,             It supports many sizes of models. You can use <code class="docutils literal notranslate"><span class="pre">wtp</span></code> to use mini model,             <code class="docutils literal notranslate"><span class="pre">wtp-tiny</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-bert-tiny</span></code> model (default),             <code class="docutils literal notranslate"><span class="pre">wtp-mini</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-bert-mini</span></code> model,             <code class="docutils literal notranslate"><span class="pre">wtp-base</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-canine-s-1l</span></code> model,             and <code class="docutils literal notranslate"><span class="pre">wtp-large</span></code> to use <code class="docutils literal notranslate"><span class="pre">wtp-canine-s-12l</span></code> model.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Example<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>Split the text based on <em>wtp</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">paragraph_tokenize</span>

<span class="n">sent</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;(1) บทความนี้ผู้เขียนสังเคราะห์ขึ้นมาจากผลงานวิจัยที่เคยทำมาในอดีต&quot;</span>
    <span class="o">+</span><span class="s2">&quot;  มิได้ทำการศึกษาค้นคว้าใหม่อย่างกว้างขวางแต่อย่างใด&quot;</span>
    <span class="o">+</span><span class="s2">&quot; จึงใคร่ขออภัยในความบกพร่องทั้งปวงมา ณ ที่นี้&quot;</span>
<span class="p">)</span>

<span class="n">paragraph_tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
<span class="c1"># output: [</span>
<span class="c1"># [&#39;(1) &#39;], </span>
<span class="c1"># [</span>
<span class="c1">#   &#39;บทความนี้ผู้เขียนสังเคราะห์ขึ้นมาจากผลงานวิจัยที่เคยทำมาในอดีต  &#39;,</span>
<span class="c1">#   &#39;มิได้ทำการศึกษาค้นคว้าใหม่อย่างกว้างขวางแต่อย่างใด &#39;,</span>
<span class="c1">#   &#39;จึงใคร่ขออภัยในความบกพร่องทั้งปวงมา &#39;,</span>
<span class="c1">#   &#39;ณ ที่นี้&#39;</span>
<span class="c1"># ]]</span>
</pre></div>
</div>
<p>Segments text into paragraphs, which can be valuable for document-level analysis or summarization.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">subword_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'tcc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#subword_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Subword tokenizer for tokenizing text into units smaller than syllables.</p>
<p>Tokenizes text into inseparable units of
Thai contiguous characters, namely
<a class="reference external" href="https://www.researchgate.net/publication/2853284_Character_Cluster_Based_Thai_Information_Retrieval">Thai Character Clusters (TCCs)</a>
TCCs are units based on Thai spelling features that could not be
separated any character further such as ‘ก็’, ‘จะ’, ‘ไม่’, and ‘ฝา’.
If the following units are separated, they could not be spelled out.
This function applies TCC rules to tokenize the text into
the smallest units.</p>
<p>For example, the word ‘ขนมชั้น’ would be tokenized
into ‘ข’, ‘น’, ‘ม’, and ‘ชั้น’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – the name of subword tokenizer</p></li>
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – keep whitespace</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of subwords</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
<dl class="simple">
<dt><strong>Options for engine</strong></dt><dd><ul class="simple">
<li><p><em>dict</em> - newmm word tokenizer with a syllable dictionary</p></li>
<li><p><em>etcc</em> - Enhanced Thai Character Cluster (Inrut et al. 2001)</p></li>
<li><p><em>han_solo</em> - CRF syllable segmenter for Thai that can work in the             Thai social media domain. See <a class="reference external" href="https://github.com/PyThaiNLP/Han-solo">PyThaiNLP/Han-solo</a>.</p></li>
<li><p><em>ssg</em> - CRF syllable segmenter for Thai. See <a class="reference external" href="https://github.com/ponrawee/ssg">ponrawee/ssg</a>.</p></li>
<li><p><em>tcc</em> (default) - Thai Character Cluster (Theeramunkong et al. 2000)</p></li>
<li><p><em>tcc_p</em> - Thai Character Cluster + improved rules that are used in newmm</p></li>
<li><p><em>tltk</em> - syllable tokenizer from tltk. See <a class="reference external" href="https://pypi.org/project/tltk/">tltk</a>.</p></li>
<li><p><em>wangchanberta</em> - SentencePiece from wangchanberta model</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Example<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>Tokenize text into subwords based on <em>tcc</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">subword_tokenize</span>

<span class="n">text_1</span> <span class="o">=</span> <span class="s2">&quot;ยุคเริ่มแรกของ ราชวงศ์หมิง&quot;</span>
<span class="n">text_2</span> <span class="o">=</span> <span class="s2">&quot;ความแปลกแยกและพัฒนาการ&quot;</span>

<span class="n">subword_tokenize</span><span class="p">(</span><span class="n">text_1</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;tcc&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ยุ&#39;, &#39;ค&#39;, &#39;เริ่ม&#39;, &#39;แร&#39;, &#39;ก&#39;,</span>
<span class="c1">#   &#39;ข&#39;, &#39;อ&#39;, &#39;ง&#39;, &#39; &#39;, &#39;รา&#39;, &#39;ช&#39;, &#39;ว&#39;, &#39;ง&#39;,</span>
<span class="c1">#   &#39;ศ&#39;, &#39;์&#39;, &#39;ห&#39;, &#39;มิ&#39;, &#39;ง&#39;]</span>

<span class="n">subword_tokenize</span><span class="p">(</span><span class="n">text_2</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;tcc&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ค&#39;, &#39;วา&#39;, &#39;ม&#39;, &#39;แป&#39;, &#39;ล&#39;, &#39;ก&#39;, &#39;แย&#39;, &#39;ก&#39;,</span>
<span class="s1">&#39;และ&#39;</span><span class="p">,</span> <span class="s1">&#39;พัฒ&#39;</span><span class="p">,</span><span class="s1">&#39;นา&#39;</span><span class="p">,</span> <span class="s1">&#39;กา&#39;</span><span class="p">,</span> <span class="s1">&#39;ร&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Tokenize text into subwords based on <em>etcc</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">text_1</span> <span class="o">=</span> <span class="s2">&quot;ยุคเริ่มแรกของ ราชวงศ์หมิง&quot;</span>
<span class="n">text_2</span> <span class="o">=</span> <span class="s2">&quot;ความแปลกแยกและพัฒนาการ&quot;</span>

<span class="n">subword_tokenize</span><span class="p">(</span><span class="n">text_1</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;etcc&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ยุคเริ่มแรกของ ราชวงศ์หมิง&#39;]</span>

<span class="n">subword_tokenize</span><span class="p">(</span><span class="n">text_2</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;etcc&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;ความแปลกแยกและ&#39;, &#39;พัฒ&#39;, &#39;นาการ&#39;]</span>
</pre></div>
</div>
<p>Tokenize text into subwords based on <em>wangchanberta</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">text_1</span> <span class="o">=</span> <span class="s2">&quot;ยุคเริ่มแรกของ ราชวงศ์หมิง&quot;</span>
<span class="n">text_2</span> <span class="o">=</span> <span class="s2">&quot;ความแปลกแยกและพัฒนาการ&quot;</span>

<span class="n">subword_tokenize</span><span class="p">(</span><span class="n">text_1</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;wangchanberta&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;▁&#39;, &#39;ยุค&#39;, &#39;เริ่มแรก&#39;, &#39;ของ&#39;, &#39;▁&#39;, &#39;ราชวงศ์&#39;, &#39;หมิง&#39;]</span>

<span class="n">subword_tokenize</span><span class="p">(</span><span class="n">text_2</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;wangchanberta&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;▁ความ&#39;, &#39;แปลก&#39;, &#39;แยก&#39;, &#39;และ&#39;, &#39;พัฒนาการ&#39;]</span>
</pre></div>
</div>
<p>Tokenizes text into subwords, which can be helpful for various NLP tasks, including subword embeddings.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">syllable_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'han_solo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#syllable_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Syllable tokenizer</p>
<p>Tokenizes text into inseparable units of
Thai syllables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – the name of syllable tokenizer</p></li>
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – keep whitespace</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of subwords</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
<dl class="simple">
<dt><strong>Options for engine</strong></dt><dd><ul class="simple">
<li><p><em>dict</em> - newmm word tokenizer with a syllable dictionary</p></li>
<li><p><em>han_solo</em> - CRF syllable segmenter for Thai that can work in the             Thai social media domain. See <a class="reference external" href="https://github.com/PyThaiNLP/Han-solo">PyThaiNLP/Han-solo</a>.</p></li>
<li><p><em>ssg</em> - CRF syllable segmenter for Thai. See <a class="reference external" href="https://github.com/ponrawee/ssg">ponrawee/ssg</a>.</p></li>
<li><p><em>tltk</em> - syllable tokenizer from tltk. See <a class="reference external" href="https://pypi.org/project/tltk/">tltk</a>.</p></li>
</ul>
</dd>
</dl>
<p>Divides text into syllables, allowing you to work with individual Thai language phonetic units.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">word_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict:</span> <span class="pre">~pythainlp.util.trie.Trie</span> <span class="pre">=</span> <span class="pre">&lt;pythainlp.util.trie.Trie</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'newmm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_broken_num:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#word_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Word tokenizer.</p>
<p>Tokenizes running text into words (list of strings).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – name of the tokenizer to be used</p></li>
<li><p><strong>custom_dict</strong> (<a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><em>pythainlp.util.Trie</em></a>) – dictionary trie (some engine may not support)</p></li>
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – True to keep whitespace, a common mark
for end of phrase in Thai.
Otherwise, whitespace is omitted.</p></li>
<li><p><strong>join_broken_num</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – True to rejoin formatted numeric that could be wrongly separated.
Otherwise, formatted numeric could be wrongly separated.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of words</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
<dl>
<dt><strong>Options for engine</strong></dt><dd><ul>
<li><p><em>attacut</em> - wrapper for
<a class="reference external" href="https://github.com/PyThaiNLP/attacut">AttaCut</a>.,
learning-based approach</p></li>
<li><p><em>deepcut</em> - wrapper for
<a class="reference external" href="https://github.com/rkcosmos/deepcut">DeepCut</a>,
learning-based approach</p></li>
<li><p><em>icu</em> - wrapper for a word tokenizer in
<a class="reference external" href="https://gitlab.pyicu.org/main/pyicu">PyICU</a>.,
from ICU (International Components for Unicode),
dictionary-based</p></li>
<li><p><em>longest</em> - dictionary-based, longest matching</p></li>
<li><p><em>mm</em> - “multi-cut”, dictionary-based, maximum matching</p></li>
<li><p><em>nercut</em> - dictionary-based, maximal matching,
constrained by Thai Character Cluster (TCC) boundaries,
combining tokens that are parts of the same named-entity</p></li>
<li><p><em>newmm</em> (default) - “new multi-cut”,
dictionary-based, maximum matching,
constrained by Thai Character Cluster (TCC) boundaries
with improved TCC rules that are used in newmm.</p></li>
<li><p><em>newmm-safe</em> - newmm, with a mechanism to avoid long
processing time for text with continuously ambiguous breaking points</p></li>
<li><p><em>nlpo3</em> - wrapper for a word tokenizer in
<a class="reference external" href="https://github.com/PyThaiNLP/nlpo3">nlpO3</a>.,
adaptation of newmm in Rust (2.5x faster)</p></li>
<li><p><em>oskut</em> - wrapper for
<a class="reference external" href="https://github.com/mrpeerat/OSKut">OSKut</a>.,
Out-of-domain StacKed cut for Word Segmentation</p></li>
<li><p><em>sefr_cut</em> - wrapper for
<a class="reference external" href="https://github.com/mrpeerat/SEFR_CUT">SEFR CUT</a>.,
Stacked Ensemble Filter and Refine for Word Segmentation</p></li>
<li><p><em>tltk</em> - wrapper for
<a class="reference external" href="https://pypi.org/project/tltk/">TLTK</a>.,</p>
<blockquote>
<div><p>maximum collocation approach</p>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Note<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p>The <strong>custom_dict</strong> parameter only works for           <em>deepcut</em>, <em>longest</em>, <em>newmm</em>, and <em>newmm-safe</em> engines.</p></li>
</ul>
</dd>
<dt class="field-even">Example<span class="colon">:</span></dt>
<dd class="field-even"><p></p></dd>
</dl>
<p>Tokenize text with different tokenizers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;โอเคบ่พวกเรารักภาษาบ้านเกิด&quot;</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;newmm&quot;</span><span class="p">)</span>
<span class="c1"># output: [&#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;รัก&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;attacut&#39;</span><span class="p">)</span>
<span class="c1"># output: [&#39;โอเค&#39;, &#39;บ่&#39;, &#39;พวกเรา&#39;, &#39;รัก&#39;, &#39;ภาษา&#39;, &#39;บ้านเกิด&#39;]</span>
</pre></div>
</div>
<p>Tokenize text with whitespace omitted:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;วรรณกรรม ภาพวาด และการแสดงงิ้ว &quot;</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;newmm&quot;</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;วรรณกรรม&#39;, &#39; &#39;, &#39;ภาพวาด&#39;, &#39; &#39;, &#39;และ&#39;, &#39;การแสดง&#39;, &#39;งิ้ว&#39;, &#39; &#39;]</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;newmm&quot;</span><span class="p">,</span> <span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># output: [&#39;วรรณกรรม&#39;, &#39;ภาพวาด&#39;, &#39;และ&#39;, &#39;การแสดง&#39;, &#39;งิ้ว&#39;]</span>
</pre></div>
</div>
<p>Join broken formatted numeric (e.g. time, decimals, IP addresses):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;เงิน1,234บาท19:32น 127.0.0.1&quot;</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;attacut&quot;</span><span class="p">,</span> <span class="n">join_broken_num</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;เงิน&#39;, &#39;1&#39;, &#39;,&#39;, &#39;234&#39;, &#39;บาท&#39;, &#39;19&#39;, &#39;:&#39;, &#39;32น&#39;, &#39; &#39;,</span>
<span class="c1">#  &#39;127&#39;, &#39;.&#39;, &#39;0&#39;, &#39;.&#39;, &#39;0&#39;, &#39;.&#39;, &#39;1&#39;]</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;attacut&quot;</span><span class="p">,</span> <span class="n">join_broken_num</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;เงิน&#39;, &#39;1,234&#39;, &#39;บาท&#39;, &#39;19:32น&#39;, &#39; &#39;, &#39;127.0.0.1&#39;]</span>
</pre></div>
</div>
<p>Tokenize with default and custom dictionaries:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.corpus.common</span> <span class="kn">import</span> <span class="n">thai_words</span>
<span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">dict_trie</span>

<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;ชินโซ อาเบะ เกิด 21 กันยายน&#39;</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;newmm&quot;</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;ชิน&#39;, &#39;โซ&#39;, &#39; &#39;, &#39;อา&#39;, &#39;เบะ&#39;, &#39; &#39;,</span>
<span class="c1">#  &#39;เกิด&#39;, &#39; &#39;, &#39;21&#39;, &#39; &#39;, &#39;กันยายน&#39;]</span>

<span class="n">custom_dict_japanese_name</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">thai_words</span><span class="p">()</span>
<span class="n">custom_dict_japanese_name</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;ชินโซ&#39;</span><span class="p">)</span>
<span class="n">custom_dict_japanese_name</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;อาเบะ&#39;</span><span class="p">)</span>

<span class="n">trie</span> <span class="o">=</span> <span class="n">dict_trie</span><span class="p">(</span><span class="n">dict_source</span><span class="o">=</span><span class="n">custom_dict_japanese_name</span><span class="p">)</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;newmm&quot;</span><span class="p">,</span> <span class="n">custom_dict</span><span class="o">=</span><span class="n">trie</span><span class="p">))</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;ชินโซ&#39;, &#39; &#39;, &#39;อาเบะ&#39;, &#39; &#39;,</span>
<span class="c1">#  &#39;เกิด&#39;, &#39; &#39;, &#39;21&#39;, &#39; &#39;, &#39;กันยายน&#39;]</span>
</pre></div>
</div>
<p>Splits text into words. This function is a fundamental tool for Thai language text analysis.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">word_detokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">segments</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'str'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#word_detokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Word detokenizer.</p>
<p>This function will detokenize the list of words in each sentence into text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>segments</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – List of sentences, each with a list of words.</p></li>
<li><p><strong>output</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – the output type (str or list)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the Thai text</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>,List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]]</p>
</dd>
<dt class="field-even">Example<span class="colon">:</span></dt>
<dd class="field-even"><p></p></dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">word_detokenize</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_detokenize</span><span class="p">([</span><span class="s2">&quot;เรา&quot;</span><span class="p">,</span> <span class="s2">&quot;เล่น&quot;</span><span class="p">]))</span>
<span class="c1"># output: เราเล่น</span>
</pre></div>
</div>
<p>Reverses the tokenization process, reconstructing text from tokenized units. Useful for text generation tasks.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pythainlp.tokenize.Tokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.</span></span><span class="sig-name descname"><span class="pre">Tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">custom_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.trie.Trie"><span class="pre">Trie</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.12)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'newmm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_broken_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#Tokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.Tokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenizer class for a custom tokenizer.</p>
<p>This class allows users to pre-define custom dictionary along with
tokenizer and encapsulate them into one single object.
It is an wrapper for both functions, that are
<code class="xref py py-func docutils literal notranslate"><span class="pre">pythainlp.tokenize.word_tokenize()</span></code>,
and <code class="xref py py-func docutils literal notranslate"><span class="pre">pythainlp.util.dict_trie()</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Example<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>Tokenizer object instantiated with <a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><code class="xref py py-class docutils literal notranslate"><span class="pre">pythainlp.util.Trie</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pythainlp.tokenize</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">pythainlp.corpus.common</span> <span class="kn">import</span> <span class="n">thai_words</span>
<span class="kn">from</span> <span class="nn">pythainlp.util</span> <span class="kn">import</span> <span class="n">dict_trie</span>

<span class="n">custom_words_list</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">thai_words</span><span class="p">())</span>
<span class="n">custom_words_list</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;อะเฟเซีย&#39;</span><span class="p">)</span>
<span class="n">custom_words_list</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;Aphasia&#39;</span><span class="p">)</span>
<span class="n">trie</span> <span class="o">=</span> <span class="n">dict_trie</span><span class="p">(</span><span class="n">dict_source</span><span class="o">=</span><span class="n">custom_words_list</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;อะเฟเซีย (Aphasia*) เป็นอาการผิดปกติของการพูด&quot;</span>
<span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">custom_dict</span><span class="o">=</span><span class="n">trie</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;newmm&#39;</span><span class="p">)</span>
<span class="n">_tokenizer</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="c1"># output: [&#39;อะเฟเซีย&#39;, &#39; &#39;, &#39;(&#39;, &#39;Aphasia&#39;, &#39;)&#39;, &#39; &#39;, &#39;เป็น&#39;, &#39;อาการ&#39;,</span>
<span class="s1">&#39;ผิดปกติ&#39;</span><span class="p">,</span> <span class="s1">&#39;ของ&#39;</span><span class="p">,</span> <span class="s1">&#39;การ&#39;</span><span class="p">,</span> <span class="s1">&#39;พูด&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Tokenizer object instantiated with a list of words:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;อะเฟเซีย (Aphasia) เป็นอาการผิดปกติของการพูด&quot;</span>
<span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">custom_dict</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">thai_words</span><span class="p">()),</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;newmm&#39;</span><span class="p">)</span>
<span class="n">_tokenizer</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;อะ&#39;, &#39;เฟเซีย&#39;, &#39; &#39;, &#39;(&#39;, &#39;Aphasia&#39;, &#39;)&#39;, &#39; &#39;, &#39;เป็น&#39;, &#39;อาการ&#39;,</span>
<span class="c1">#   &#39;ผิดปกติ&#39;, &#39;ของ&#39;, &#39;การ&#39;, &#39;พูด&#39;]</span>
</pre></div>
</div>
<p>Tokenizer object instantiated with a file path containing a list of
words separated with <em>newline</em> and explicitly setting a new tokenizer
after initiation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">PATH_TO_CUSTOM_DICTIONARY</span> <span class="o">=</span> <span class="s1">&#39;./custom_dictionary.txtt&#39;</span>

<span class="c1"># write a file</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">PATH_TO_CUSTOM_DICTIONARY</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;อะเฟเซีย</span><span class="se">\n</span><span class="s1">Aphasia</span><span class="se">\n</span><span class="s1">ผิด</span><span class="se">\n</span><span class="s1">ปกติ&#39;</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;อะเฟเซีย (Aphasia) เป็นอาการผิดปกติของการพูด&quot;</span>

<span class="c1"># initiate an object from file with `attacut` as tokenizer</span>
<span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">custom_dict</span><span class="o">=</span><span class="n">PATH_TO_CUSTOM_DICTIONARY</span><span class="p">,</span> \
    <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;attacut&#39;</span><span class="p">)</span>

<span class="n">_tokenizer</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;อะเฟเซีย&#39;, &#39; &#39;, &#39;(&#39;, &#39;Aphasia&#39;, &#39;)&#39;, &#39; &#39;, &#39;เป็น&#39;, &#39;อาการ&#39;, &#39;ผิด&#39;,</span>
<span class="c1">#   &#39;ปกติ&#39;, &#39;ของ&#39;, &#39;การ&#39;, &#39;พูด&#39;]</span>

<span class="c1"># change tokenizer to `newmm`</span>
<span class="n">_tokenizer</span><span class="o">.</span><span class="n">set_tokenizer_engine</span><span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;newmm&#39;</span><span class="p">)</span>
<span class="n">_tokenizer</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="c1"># output:</span>
<span class="c1"># [&#39;อะเฟเซีย&#39;, &#39; &#39;, &#39;(&#39;, &#39;Aphasia&#39;, &#39;)&#39;, &#39; &#39;, &#39;เป็นอาการ&#39;, &#39;ผิด&#39;,</span>
<span class="c1">#   &#39;ปกติ&#39;, &#39;ของการพูด&#39;]</span>
</pre></div>
</div>
<p>The <cite>Tokenizer</cite> class is a versatile tool for customizing tokenization processes and managing tokenization models. It provides various methods and attributes to fine-tune tokenization according to your specific needs.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.Tokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">custom_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.trie.Trie"><span class="pre">Trie</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(in Python v3.12)"><span class="pre">Iterable</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'newmm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_broken_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#Tokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.Tokenizer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize tokenizer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>custom_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – a file path, a list of vocaburaies* to be
used to create a trie, or an instantiated
<a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><code class="xref py py-class docutils literal notranslate"><span class="pre">pythainlp.util.Trie</span></code></a> object.</p></li>
<li><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – choose between different options of tokenizer engines
(i.e.  <em>newmm</em>, <em>mm</em>, <em>longest</em>, <em>deepcut</em>)</p></li>
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – True to keep whitespace, a common mark
for end of phrase in Thai</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.Tokenizer.word_tokenize">
<span class="sig-name descname"><span class="pre">word_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#Tokenizer.word_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.Tokenizer.word_tokenize" title="Permalink to this definition"></a></dt>
<dd><p>Main tokenization function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of words, tokenized from the text</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.Tokenizer.set_tokenize_engine">
<span class="sig-name descname"><span class="pre">set_tokenize_engine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/core.html#Tokenizer.set_tokenize_engine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.Tokenizer.set_tokenize_engine" title="Permalink to this definition"></a></dt>
<dd><p>Set the tokenizer’s engine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>engine</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – choose between different options of tokenizer engines
(i.e. <em>newmm</em>, <em>mm</em>, <em>longest</em>, <em>deepcut</em>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="tokenization-engines">
<h2>Tokenization Engines<a class="headerlink" href="#tokenization-engines" title="Permalink to this heading"></a></h2>
<p>This module offers multiple tokenization engines designed for different levels of text analysis.</p>
</section>
<section id="sentence-level">
<h2>Sentence level<a class="headerlink" href="#sentence-level" title="Permalink to this heading"></a></h2>
<p><strong>crfcut</strong></p>
<span class="target" id="module-pythainlp.tokenize.crfcut"></span><p>CRFCut - Thai sentence segmenter.</p>
<p>Thai sentence segmentation using conditional random field,
with default model trained on TED dataset</p>
<p>Performance:
- ORCHID - space-correct accuracy 87% vs 95% state-of-the-art</p>
<blockquote>
<div><p>(Zhou et al, 2016; <a class="reference external" href="https://www.aclweb.org/anthology/C16-1031.pdf">https://www.aclweb.org/anthology/C16-1031.pdf</a>)</p>
</div></blockquote>
<ul class="simple">
<li><p>TED dataset - space-correct accuracy 82%</p></li>
</ul>
<p>See development notebooks at <a class="reference external" href="https://github.com/vistec-AI/ted_crawler">https://github.com/vistec-AI/ted_crawler</a>;
POS features are not used due to unreliable POS tagging available</p>
<p>A tokenizer that operates at the sentence level using Conditional Random Fields (CRF). It is suitable for segmenting text into sentences accurately.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.crfcut.extract_features">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.crfcut.</span></span><span class="sig-name descname"><span class="pre">extract_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">doc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_n_gram</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/crfcut.html#extract_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.crfcut.extract_features" title="Permalink to this definition"></a></dt>
<dd><p>Extract features for CRF by sliding <cite>max_n_gram</cite> of tokens
for +/- <cite>window</cite> from the current token</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>doc</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>]</em>) – tokens from which features are to be extracted</p></li>
<li><p><strong>window</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – size of window before and after the current token</p></li>
<li><p><strong>max_n_gram</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – create n_grams from 1-gram to <cite>max_n_gram</cite>-gram     within the <cite>window</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of lists of features to be fed to CRF</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.crfcut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.crfcut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/crfcut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.crfcut.segment" title="Permalink to this definition"></a></dt>
<dd><p>CRF-based sentence segmentation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into sentences</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of words, tokenized from the text</p>
</dd>
</dl>
</dd></dl>

<p><strong>thaisumcut</strong></p>
<span class="target" id="module-pythainlp.tokenize.thaisumcut"></span><p>The implementation of sentence segmentator from Nakhun Chumpolsathien, 2020
original codes are from: <a class="reference external" href="https://github.com/nakhunchumpolsathien/ThaiSum">https://github.com/nakhunchumpolsathien/ThaiSum</a></p>
<p>Cite:</p>
<dl class="simple">
<dt>&#64;mastersthesis{chumpolsathien_2020,</dt><dd><p>title={Using Knowledge Distillation from Keyword Extraction to Improve the Informativeness of Neural Cross-lingual Summarization},
author={Chumpolsathien, Nakhun},
year={2020},
school={Beijing Institute of Technology}</p>
</dd>
</dl>
<p>A sentence tokenizer based on a maximum entropy model. It’s a great choice for sentence boundary detection in Thai text.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.thaisumcut.list_to_string">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.thaisumcut.</span></span><span class="sig-name descname"><span class="pre">list_to_string</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/thaisumcut.html#list_to_string"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.thaisumcut.list_to_string" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.thaisumcut.middle_cut">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.thaisumcut.</span></span><span class="sig-name descname"><span class="pre">middle_cut</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentences</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/thaisumcut.html#middle_cut"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.thaisumcut.middle_cut" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pythainlp.tokenize.thaisumcut.ThaiSentenceSegmentor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.thaisumcut.</span></span><span class="sig-name descname"><span class="pre">ThaiSentenceSegmentor</span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/thaisumcut.html#ThaiSentenceSegmentor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.thaisumcut.ThaiSentenceSegmentor" title="Permalink to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.thaisumcut.ThaiSentenceSegmentor.split_into_sentences">
<span class="sig-name descname"><span class="pre">split_into_sentences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">isMiddleCut</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/thaisumcut.html#ThaiSentenceSegmentor.split_into_sentences"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.thaisumcut.ThaiSentenceSegmentor.split_into_sentences" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="word-level">
<h2>Word level<a class="headerlink" href="#word-level" title="Permalink to this heading"></a></h2>
<p><strong>attacut</strong></p>
<span class="target" id="module-pythainlp.tokenize.attacut"></span><p>Wrapper for AttaCut - Fast and Reasonably Accurate Word Tokenizer for Thai</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/PyThaiNLP/attacut">GitHub repository</a></p></li>
</ul>
</dd>
</dl>
<p>A tokenizer designed for word-level segmentation. It provides accurate word boundary detection in Thai text.</p>
<dl class="py class">
<dt class="sig sig-object py" id="pythainlp.tokenize.attacut.AttacutTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.attacut.</span></span><span class="sig-name descname"><span class="pre">AttacutTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'attacut-sc'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/attacut.html#AttacutTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.attacut.AttacutTokenizer" title="Permalink to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.attacut.AttacutTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'attacut-sc'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/attacut.html#AttacutTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.attacut.AttacutTokenizer.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.attacut.AttacutTokenizer.tokenize">
<span class="sig-name descname"><span class="pre">tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/attacut.html#AttacutTokenizer.tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.attacut.AttacutTokenizer.tokenize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.attacut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.attacut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'attacut-sc'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/attacut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.attacut.segment" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper for AttaCut - Fast and Reasonably Accurate Word Tokenizer for Thai
:param str text: text to be tokenized to words
:param str model: model of word tokenizer model
:return: list of words, tokenized from the text
:rtype: list[str]
<strong>Options for model</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><em>attacut-sc</em> (default) using both syllable and character features</p></li>
<li><p><em>attacut-c</em> using only character feature</p></li>
</ul>
</div></blockquote>
</dd></dl>

<p><strong>deepcut</strong></p>
<span class="target" id="module-pythainlp.tokenize.deepcut"></span><p>Wrapper for deepcut Thai word segmentation. deepcut is a
Thai word segmentation library using 1D Convolution Neural Network.</p>
<p>User need to install deepcut (and its dependency: tensorflow) by themselves.</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/rkcosmos/deepcut">GitHub repository</a></p></li>
</ul>
</dd>
</dl>
<p>Utilizes deep learning techniques for word segmentation, achieving high accuracy and performance.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.deepcut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.deepcut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.trie.Trie"><span class="pre">Trie</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/deepcut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.deepcut.segment" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<p><strong>multi_cut</strong></p>
<span class="target" id="module-pythainlp.tokenize.multi_cut"></span><p>Multi cut – Thai word segmentation with maximum matching.
Original codes from Korakot Chaovavanich.</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://www.facebook.com/groups/408004796247683/permalink/431283740586455/">Facebook post</a></p></li>
<li><p><a class="reference external" href="https://gist.github.com/korakot/fe26c65dc9eed467f4497f784a805716">GitHub Gist</a></p></li>
</ul>
</dd>
</dl>
<p>An ensemble tokenizer that combines multiple tokenization strategies for improved word segmentation.</p>
<dl class="py class">
<dt class="sig sig-object py" id="pythainlp.tokenize.multi_cut.LatticeString">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.multi_cut.</span></span><span class="sig-name descname"><span class="pre">LatticeString</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/multi_cut.html#LatticeString"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.multi_cut.LatticeString" title="Permalink to this definition"></a></dt>
<dd><p>String that keeps possible tokenizations</p>
<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.multi_cut.LatticeString.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/multi_cut.html#LatticeString.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.multi_cut.LatticeString.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.multi_cut.mmcut">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.multi_cut.</span></span><span class="sig-name descname"><span class="pre">mmcut</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/multi_cut.html#mmcut"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.multi_cut.mmcut" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.multi_cut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.multi_cut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict:</span> <span class="pre">~pythainlp.util.trie.Trie</span> <span class="pre">=</span> <span class="pre">&lt;pythainlp.util.trie.Trie</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/multi_cut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.multi_cut.segment" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary-based maximum matching word segmentation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>custom_dict</strong> (<a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><em>Trie</em></a><em>, </em><em>optional</em>) – tokenization dictionary,        defaults to DEFAULT_WORD_DICT_TRIE</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of segmented tokens</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.multi_cut.find_all_segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.multi_cut.</span></span><span class="sig-name descname"><span class="pre">find_all_segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict:</span> <span class="pre">~pythainlp.util.trie.Trie</span> <span class="pre">=</span> <span class="pre">&lt;pythainlp.util.trie.Trie</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/multi_cut.html#find_all_segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.multi_cut.find_all_segment" title="Permalink to this definition"></a></dt>
<dd><p>Get all possible segment variations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – input string to be tokenized</p></li>
<li><p><strong>custom_dict</strong> (<a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><em>Trie</em></a><em>, </em><em>optional</em>) – tokenization dictionary,        defaults to DEFAULT_WORD_DICT_TRIE</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of segment variations</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<p><strong>nlpo3</strong></p>
<span class="target" id="module-pythainlp.tokenize.nlpo3"></span><p>A word tokenizer based on the NLPO3 model. It offers advanced word boundary detection and is suitable for various NLP tasks.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.nlpo3.load_dict">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.nlpo3.</span></span><span class="sig-name descname"><span class="pre">load_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dict_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/nlpo3.html#load_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.nlpo3.load_dict" title="Permalink to this definition"></a></dt>
<dd><p>Load a dictionary file into an in-memory dictionary collection.</p>
<p>The loaded dictionary will be accessible through the assigned dict_name.
<strong>* This function does not override an existing dict name. *</strong></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – Path to a dictionary file</p></li>
<li><p><strong>dict_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – A unique dictionary name, used for reference.</p></li>
</ul>
</dd>
</dl>
<p>:return bool</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/PyThaiNLP/nlpo3">https://github.com/PyThaiNLP/nlpo3</a></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.nlpo3.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.nlpo3.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'_67a47bf9'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">safe_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/nlpo3.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.nlpo3.segment" title="Permalink to this definition"></a></dt>
<dd><p>Break text into tokens.</p>
<p>Python binding for nlpO3. It is newmm engine in Rust.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>custom_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – dictionary name, as assigned with load_dict(),        defaults to pythainlp/corpus/common/words_th.txt</p></li>
<li><p><strong>safe_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – reduce chance for long processing time for long text        with many ambiguous breaking points, defaults to False</p></li>
<li><p><strong>parallel_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – Use multithread mode, defaults to False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of tokens</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
<dt class="field-even">See Also<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/PyThaiNLP/nlpo3">https://github.com/PyThaiNLP/nlpo3</a></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p><strong>longest</strong></p>
<span class="target" id="module-pythainlp.tokenize.longest"></span><p>Dictionary-based longest-matching Thai word segmentation. Implementation is based
on the codes from Patorn Utenpattanun.</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/patorn/thaitokenizer/blob/master/thaitokenizer/tokenizer.py">GitHub Repository</a></p></li>
</ul>
</dd>
</dl>
<p>A tokenizer that identifies word boundaries by selecting the longest possible words in a text.</p>
<dl class="py class">
<dt class="sig sig-object py" id="pythainlp.tokenize.longest.LongestMatchTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.longest.</span></span><span class="sig-name descname"><span class="pre">LongestMatchTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trie</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.trie.Trie"><span class="pre">Trie</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/longest.html#LongestMatchTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.longest.LongestMatchTokenizer" title="Permalink to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.longest.LongestMatchTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trie</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.trie.Trie"><span class="pre">Trie</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/longest.html#LongestMatchTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.longest.LongestMatchTokenizer.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.longest.LongestMatchTokenizer.tokenize">
<span class="sig-name descname"><span class="pre">tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/longest.html#LongestMatchTokenizer.tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.longest.LongestMatchTokenizer.tokenize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.longest.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.longest.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict:</span> <span class="pre">~pythainlp.util.trie.Trie</span> <span class="pre">=</span> <span class="pre">&lt;pythainlp.util.trie.Trie</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/longest.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.longest.segment" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary-based longest matching word segmentation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into words</p></li>
<li><p><strong>custom_dict</strong> (<a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><em>pythainlp.util.Trie</em></a>) – dictionary for tokenization</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of words, tokenized from the text</p>
</dd>
</dl>
</dd></dl>

<p><strong>pyicu</strong></p>
<span class="target" id="module-pythainlp.tokenize.pyicu"></span><p>Wrapper for PyICU word segmentation. This wrapper module uses
<code class="xref py py-class docutils literal notranslate"><span class="pre">icu.BreakIterator</span></code> with Thai as <code class="xref py py-class docutils literal notranslate"><span class="pre">icu.Local</span></code>
to locate boundaries between words in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/ovalhub/pyicu">GitHub repository</a></p></li>
</ul>
</dd>
</dl>
<p>An ICU-based word tokenizer offering robust support for Thai text segmentation.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.pyicu.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.pyicu.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/pyicu.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.pyicu.segment" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into words</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of words, tokenized from the text</p>
</dd>
</dl>
</dd></dl>

<p><strong>nercut</strong></p>
<span class="target" id="module-pythainlp.tokenize.nercut"></span><p>nercut 0.2</p>
<p>Dictionary-based maximal matching word segmentation, constrained by
Thai Character Cluster (TCC) boundaries, and combining tokens that are
parts of the same named entity.</p>
<p>Code by Wannaphong Phatthiyaphaibun</p>
<p>A tokenizer optimized for Named Entity Recognition (NER) tasks, ensuring accurate tokenization for entity recognition.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.nercut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.nercut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">text:</span> <span class="pre">str,</span> <span class="pre">taglist:</span> <span class="pre">~typing.Iterable[str]</span> <span class="pre">=</span> <span class="pre">['ORGANIZATION',</span> <span class="pre">'PERSON',</span> <span class="pre">'PHONE',</span> <span class="pre">'EMAIL',</span> <span class="pre">'DATE',</span> <span class="pre">'TIME'],</span> <span class="pre">tagger=&lt;pythainlp.tag.named_entity.NER</span> <span class="pre">object&gt;</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/nercut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.nercut.segment" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary-based maximal matching word segmentation, constrained by
Thai Character Cluster (TCC) boundaries, and combining tokens that are
parts of the same named-entity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into words</p></li>
<li><p><strong>taglist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a>) – a list of named entity tags to be used</p></li>
<li><p><strong>tagger</strong> (<em>class</em>) – NER tagger engine</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of words, tokenized from the text</p>
</dd>
</dl>
</dd></dl>

<p><strong>sefr_cut</strong></p>
<span class="target" id="module-pythainlp.tokenize.sefr_cut"></span><p>Wrapper for SEFR CUT Thai word segmentation. SEFR CUT is a
Thai Word Segmentation Models using Stacked Ensemble.</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/mrpeerat/SEFR_CUT">GitHub repository</a></p></li>
</ul>
</dd>
</dl>
<p>An advanced word tokenizer for segmenting Thai text, with a focus on precision.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.sefr_cut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.sefr_cut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ws1000'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/sefr_cut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.sefr_cut.segment" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<p><strong>oskut</strong></p>
<span class="target" id="module-pythainlp.tokenize.oskut"></span><p>Wrapper OSKut (Out-of-domain StacKed cut for Word Segmentation).
Handling Cross- and Out-of-Domain Samples in Thai Word Segmentation
Stacked Ensemble Framework and DeepCut as Baseline model (ACL 2021 Findings)</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://github.com/mrpeerat/OSKut">GitHub repository</a></p></li>
</ul>
</dd>
</dl>
<p>A tokenizer that uses a pre-trained model for word segmentation. It’s a reliable choice for general-purpose text analysis.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.oskut.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.oskut.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ws'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/oskut.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.oskut.segment" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<p><strong>newmm (Default)</strong></p>
<span class="target" id="module-pythainlp.tokenize.newmm"></span><p>Dictionary-based maximal matching word segmentation, constrained by
Thai Character Cluster (TCC) boundaries with improved rules.</p>
<p>The codes are based on the notebooks created by Korakot Chaovavanich,
with heuristic graph size limit added to avoid exponential waiting time.</p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/notebook#fileId=1V1Z657_5eSWPo8rLfVRwA0A5E4vkg7SI">https://colab.research.google.com/notebook#fileId=1V1Z657_5eSWPo8rLfVRwA0A5E4vkg7SI</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/drive/14Ibg-ngZXj15RKwjNwoZlOT32fQBOrBx#scrollTo=MYZ7NzAR7Dmw">https://colab.research.google.com/drive/14Ibg-ngZXj15RKwjNwoZlOT32fQBOrBx#scrollTo=MYZ7NzAR7Dmw</a></p></li>
</ul>
</dd>
</dl>
<p>The default word tokenization engine that provides a balance between accuracy and efficiency for most use cases.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.newmm.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.newmm.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_dict:</span> <span class="pre">~pythainlp.util.trie.Trie</span> <span class="pre">=</span> <span class="pre">&lt;pythainlp.util.trie.Trie</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">safe_mode:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/newmm.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.newmm.segment" title="Permalink to this definition"></a></dt>
<dd><p>Maximal-matching word segmentation constrained by Thai Character Cluster.</p>
<p>A dictionary-based word segmentation using maximal matching algorithm,
constrained by Thai Character Cluster boundaries.</p>
<p>A custom dictionary can be supplied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized</p></li>
<li><p><strong>custom_dict</strong> (<a class="reference internal" href="util.html#pythainlp.util.Trie" title="pythainlp.util.Trie"><em>Trie</em></a><em>, </em><em>optional</em>) – tokenization dictionary,        defaults to DEFAULT_WORD_DICT_TRIE</p></li>
<li><p><strong>safe_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – reduce chance for long processing time for long text        with many ambiguous breaking points, defaults to False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of tokens</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="subword-level">
<h2>Subword level<a class="headerlink" href="#subword-level" title="Permalink to this heading"></a></h2>
<p><strong>tcc</strong></p>
<span class="target" id="module-pythainlp.tokenize.tcc"></span><p>The implementation of tokenizer according to Thai Character Clusters (TCCs)
rules proposed by <a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2548">Theeramunkong et al. 2000.</a></p>
<dl class="simple">
<dt>Credits:</dt><dd><ul class="simple">
<li><p>TCC: Jakkrit TeCho</p></li>
<li><p>Grammar: Wittawat Jitkrittum (<a class="reference external" href="https://github.com/wittawatj/jtcc/blob/master/TCC.g">link to the source file</a>)</p></li>
<li><p>Python code: Korakot Chaovavanich</p></li>
</ul>
</dd>
</dl>
<p>Tokenizes text into Thai Character Clusters (TCCs), a subword level representation.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.tcc.tcc">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.tcc.</span></span><span class="sig-name descname"><span class="pre">tcc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/tcc.html#tcc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.tcc.tcc" title="Permalink to this definition"></a></dt>
<dd><p>TCC generator which generates Thai Character Clusters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>subwords (character clusters)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.tcc.tcc_pos">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.tcc.</span></span><span class="sig-name descname"><span class="pre">tcc_pos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Set" title="(in Python v3.12)"><span class="pre">Set</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/tcc.html#tcc_pos"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.tcc.tcc_pos" title="Permalink to this definition"></a></dt>
<dd><p>TCC positions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of the ending position of subwords</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#set" title="(in Python v3.12)">set</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.tcc.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.tcc.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/tcc.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.tcc.segment" title="Permalink to this definition"></a></dt>
<dd><p>Subword segmentation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of subwords (character clusters), tokenized from the text</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<p><strong>tcc+</strong></p>
<span class="target" id="module-pythainlp.tokenize.tcc_p"></span><p>The implementation of tokenizer according to Thai Character Clusters (TCCs)
rules proposed by <a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2548">Theeramunkong et al. 2000.</a>
and improved rules that are used in newmm</p>
<dl class="simple">
<dt>Credits:</dt><dd><ul class="simple">
<li><p>TCC: Jakkrit TeCho</p></li>
<li><p>Grammar: Wittawat Jitkrittum (<a class="reference external" href="https://github.com/wittawatj/jtcc/blob/master/TCC.g">link to the source file</a>)</p></li>
<li><p>Python code: Korakot Chaovavanich</p></li>
</ul>
</dd>
</dl>
<p>A subword tokenizer that includes additional rules for more precise subword segmentation.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.tcc_p.tcc">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.tcc_p.</span></span><span class="sig-name descname"><span class="pre">tcc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/tcc_p.html#tcc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.tcc_p.tcc" title="Permalink to this definition"></a></dt>
<dd><p>TCC generator which generates Thai Character Clusters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>subwords (character clusters)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.tcc_p.tcc_pos">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.tcc_p.</span></span><span class="sig-name descname"><span class="pre">tcc_pos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Set" title="(in Python v3.12)"><span class="pre">Set</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/tcc_p.html#tcc_pos"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.tcc_p.tcc_pos" title="Permalink to this definition"></a></dt>
<dd><p>TCC positions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of the ending position of subwords</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#set" title="(in Python v3.12)">set</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.tcc_p.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.tcc_p.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/tcc_p.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.tcc_p.segment" title="Permalink to this definition"></a></dt>
<dd><p>Subword segmentation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of subwords (character clusters), tokenized from the text</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<p><strong>etcc</strong></p>
<span class="target" id="module-pythainlp.tokenize.etcc"></span><p>Segmenting text into Enhanced Thai Character Clusters (ETCCs)
Python implementation by Wannaphong Phatthiyaphaibun</p>
<p>This implementation relies on a dictionary of ETCC created from etcc.txt
in pythainlp/corpus.</p>
<p>Notebook:
<a class="reference external" href="https://colab.research.google.com/drive/1UTQgxxMRxOr9Jp1B1jcq1frBNvorhtBQ">https://colab.research.google.com/drive/1UTQgxxMRxOr9Jp1B1jcq1frBNvorhtBQ</a></p>
<dl class="field-list simple">
<dt class="field-odd">See Also<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>Jeeragone Inrut, Patiroop Yuanghirun, Sarayut Paludkong, Supot Nitsuwat, and
Para Limmaneepraserth. “Thai word segmentation using combination of forward
and backward longest matching techniques.” In International Symposium on
Communications and Information Technology (ISCIT), pp. 37-40. 2001.</p>
<p>Enhanced Thai Character Clusters (eTCC) tokenizer for subword-level analysis.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.etcc.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.etcc.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/etcc.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.etcc.segment" title="Permalink to this definition"></a></dt>
<dd><p>Segmenting text into ETCCs.</p>
<p>Enhanced Thai Character Cluster (ETCC) is a kind of subword unit.
The concept was presented in Inrut, Jeeragone, Patiroop Yuanghirun,
Sarayut Paludkong, Supot Nitsuwat, and Para Limmaneepraserth.
“Thai word segmentation using combination of forward and backward
longest matching techniques.” In International Symposium on Communications
and Information Technology (ISCIT), pp. 37-40. 2001.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – text to be tokenized into character clusters</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of clusters, tokenized from the text</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

<p><strong>han_solo</strong></p>
<span class="target" id="module-pythainlp.tokenize.han_solo"></span><p>🪿 Han-solo: Thai syllable segmenter</p>
<p>GitHub: <a class="reference external" href="https://github.com/PyThaiNLP/Han-solo">https://github.com/PyThaiNLP/Han-solo</a></p>
<p>A subword tokenizer specialized for Han characters and mixed scripts, suitable for various text processing scenarios.</p>
<dl class="py class">
<dt class="sig sig-object py" id="pythainlp.tokenize.han_solo.Featurizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.han_solo.</span></span><span class="sig-name descname"><span class="pre">Featurizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delimiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/han_solo.html#Featurizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.han_solo.Featurizer" title="Permalink to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.han_solo.Featurizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delimiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/han_solo.html#Featurizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.han_solo.Featurizer.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.han_solo.Featurizer.pad">
<span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'#'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/han_solo.html#Featurizer.pad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.han_solo.Featurizer.pad" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pythainlp.tokenize.han_solo.Featurizer.featurize">
<span class="sig-name descname"><span class="pre">featurize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indiv_char</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'list'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pythainlp/tokenize/han_solo.html#Featurizer.featurize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.han_solo.Featurizer.featurize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pythainlp.tokenize.han_solo.segment">
<span class="sig-prename descclassname"><span class="pre">pythainlp.tokenize.han_solo.</span></span><span class="sig-name descname"><span class="pre">segment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.12)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pythainlp/tokenize/han_solo.html#segment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pythainlp.tokenize.han_solo.segment" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tag.html" class="btn btn-neutral float-left" title="pythainlp.tag" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tools.html" class="btn btn-neutral float-right" title="pythainlp.tools" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017-2024, PyThaiNLP (Apache Software License 2.0).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>